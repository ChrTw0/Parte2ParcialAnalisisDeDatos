# Tarifarios Scraper - Estructura del Proyecto

## ğŸ“ Estructura de Directorios

```
PARTE 2/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # ConfiguraciÃ³n global
â”‚   â”œâ”€â”€ api/                     # API FastAPI
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py             # Endpoints de la API
â”‚   â”œâ”€â”€ models/                  # Modelos de datos (Pydantic)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ tarifario.py        # Modelos de tarifarios
â”‚   â”œâ”€â”€ scrapers/                # Scrapers por banco
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py             # Clase base abstracta
â”‚   â”‚   â”œâ”€â”€ bbva.py             # Scraper BBVA
â”‚   â”‚   â”œâ”€â”€ bcp.py              # Scraper BCP
â”‚   â”‚   â”œâ”€â”€ interbank.py        # Scraper Interbank
â”‚   â”‚   â”œâ”€â”€ scotiabank.py       # Scraper Scotiabank
â”‚   â”‚   â””â”€â”€ banco_nacion.py     # Scraper Banco de la NaciÃ³n
â”‚   â””â”€â”€ utils/                   # Utilidades
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ downloader.py       # Descarga de PDFs
â”‚       â””â”€â”€ logger.py           # ConfiguraciÃ³n de logs
â”œâ”€â”€ scripts/                     # Scripts CLI
â”‚   â””â”€â”€ run_scraper.py          # Script principal de scraping
â”œâ”€â”€ tests/                       # Tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unit/                   # Tests unitarios
â”‚   â”œâ”€â”€ integration/            # Tests de integraciÃ³n
â”‚   â””â”€â”€ test_scrapers.py        # Tests de scrapers
â”œâ”€â”€ data/                        # Datos procesados
â”‚   â”œâ”€â”€ raw/                    # Datos crudos
â”‚   â””â”€â”€ processed/              # Datos procesados
â”œâ”€â”€ TARIFARIOS/                  # PDFs descargados
â”‚   â”œâ”€â”€ BBVA_Continental/
â”‚   â”œâ”€â”€ BCP/
â”‚   â”œâ”€â”€ Interbank/
â”‚   â”œâ”€â”€ Scotiabank/
â”‚   â””â”€â”€ Banco_de_la_NaciÃ³n/
â”œâ”€â”€ logs/                        # Logs de la aplicaciÃ³n
â”œâ”€â”€ requirements.txt             # Dependencias
â”œâ”€â”€ .env.example                # Ejemplo de variables de entorno
â”œâ”€â”€ .gitignore
â””â”€â”€ README_PROYECTO.md          # Este archivo
```

## ğŸš€ InstalaciÃ³n

### 1. Crear entorno virtual

```bash
python -m venv venv
```

### 2. Activar entorno virtual

**Windows:**
```bash
venv\Scripts\activate
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno

```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

## ğŸ“‹ Uso

### OpciÃ³n 1: API FastAPI

**Iniciar servidor:**
```bash
python -m src.api.main
# O usando uvicorn directamente:
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

**Endpoints disponibles:**

- `GET /` - InformaciÃ³n del proyecto
- `GET /health` - Health check
- `GET /bancos` - Listar bancos disponibles
- `POST /scrape/{banco}` - Scrapear URLs de un banco
- `POST /download/{banco}` - Descargar PDFs de un banco
- `POST /download/all` - Descargar todos los tarifarios

**Ejemplos con curl:**

```bash
# Listar bancos
curl http://localhost:8000/bancos

# Scrapear BBVA
curl -X POST http://localhost:8000/scrape/BBVA%20Continental

# Descargar tarifarios de BCP
curl -X POST http://localhost:8000/download/BCP

# Descargar todos
curl -X POST http://localhost:8000/download/all
```

**DocumentaciÃ³n interactiva:**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### OpciÃ³n 2: Script CLI

```bash
python scripts/run_scraper.py
```

Esto ejecutarÃ¡ el scraping de todos los bancos y descargarÃ¡ los PDFs automÃ¡ticamente.

### OpciÃ³n 3: Uso programÃ¡tico

```python
from src.scrapers import BBVAScraper
from src.utils import PDFDownloader

# Scrapear URLs
with BBVAScraper() as scraper:
    urls = scraper.obtener_urls()
    print(f"Encontradas {len(urls)} URLs")

# Descargar PDFs
downloader = PDFDownloader()
for url in urls:
    resultado = downloader.descargar(url)
    if resultado.exito:
        print(f"âœ… {resultado.metadata.nombre_archivo}")
```

## ğŸ§ª Tests

```bash
# Ejecutar todos los tests
pytest

# Con cobertura
pytest --cov=src tests/

# Test especÃ­fico
pytest tests/test_scrapers.py -v
```

## ğŸ—ï¸ Arquitectura

### PatrÃ³n de DiseÃ±o

El proyecto utiliza:
- **Strategy Pattern**: Cada banco tiene su propio scraper que implementa `BaseScraper`
- **Dependency Injection**: ConfiguraciÃ³n centralizada en `settings`
- **Repository Pattern**: SeparaciÃ³n de lÃ³gica de scraping y descarga

### Flujo de Datos

```
1. API/CLI Request
   â†“
2. Scraper especÃ­fico (BBVA, BCP, etc.)
   â†“
3. ExtracciÃ³n de URLs desde HTML
   â†“
4. PDFDownloader
   â†“
5. Descarga y almacenamiento
   â†“
6. GeneraciÃ³n de metadata
   â†“
7. Response con resultados
```

### Modelos de Datos

- **TarifarioURL**: URL de un PDF con metadata
- **TarifarioMetadata**: Metadata de un PDF descargado
- **ScrapingResult**: Resultado de un proceso de scraping
- **DownloadResult**: Resultado de una descarga

## ğŸ”§ ConfiguraciÃ³n

Archivo `.env`:

```env
# API
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# Paths
DATA_DIR=./data
TARIFARIOS_DIR=./TARIFARIOS

# Scraping
USER_AGENT="Mozilla/5.0..."
REQUEST_TIMEOUT=30
RETRY_ATTEMPTS=3
DELAY_BETWEEN_REQUESTS=1
```

## ğŸ“Š Bancos Soportados

| Banco | Scraper | Estado | MÃ©todo |
|-------|---------|--------|--------|
| BBVA Continental | âœ… | Implementado | BeautifulSoup |
| BCP | âœ… | Implementado | BeautifulSoup |
| Interbank | âœ… | Implementado | BeautifulSoup |
| Scotiabank | âš ï¸ | Pendiente | Selenium requerido |
| Banco de la NaciÃ³n | âœ… | Implementado | URLs hardcodeadas |

## ğŸ› Troubleshooting

### Error: "No module named 'src'"

```bash
# Ejecutar desde la raÃ­z del proyecto:
python -m src.api.main
# No: python src/api/main.py
```

### Error al descargar PDFs

Verificar:
1. URLs vÃ¡lidas
2. ConexiÃ³n a internet
3. Permisos de escritura en carpeta TARIFARIOS
4. User-Agent vÃ¡lido en configuraciÃ³n

## ğŸ“ TODO

- [ ] Implementar scraper de Scotiabank con Selenium
- [ ] Agregar cachÃ© de URLs scrapeadas
- [ ] Implementar sistema de notificaciones
- [ ] Agregar validaciÃ³n de integridad de PDFs
- [ ] Implementar extracciÃ³n automÃ¡tica de datos de PDFs
- [ ] Agregar base de datos para almacenar metadata
- [ ] Implementar sistema de versionado de tarifarios
- [ ] Agregar comparaciÃ³n de tarifas entre bancos

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad Nacional de IngenierÃ­a

---

**Grupo 2** - AnalÃ­tica de Datos
Fecha: Octubre 2025
